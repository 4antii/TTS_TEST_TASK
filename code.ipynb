{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YVector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "import zipfile\n",
        "import torchaudio\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "0RQ_sQrG52Ts"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dOsqpUE1Aq4",
        "outputId": "05399529-847f-4de2-bd19-8e79af8e402c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PeJGc66Pqeu",
        "outputId": "d4905f31-70d6-4370-9a75-6638ad4b0045"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распаковка трейна и теста с Google Drive"
      ],
      "metadata": {
        "id": "6FPzRV-A-hjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('./drive/MyDrive/YVector/Voxceleb/features.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ],
      "metadata": {
        "id": "2rEvK2gd1Ejw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip_file = './drive/MyDrive/YVector/Voxceleb/vox1_test_wav.zip'\n",
        "directory_to_extract_to = './test'\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "metadata": {
        "id": "H9vu3oJW0hhv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./drive/MyDrive/YVector/Voxceleb/veri_test.txt ./"
      ],
      "metadata": {
        "id": "tp6Zbtj90yGk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 1251\n",
        "embedding_dim = 128"
      ],
      "metadata": {
        "id": "hT7OvTN9QBWe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этот лоадер загружаются заранее обрезанные и нормализованные данные в виде npy массивов"
      ],
      "metadata": {
        "id": "U5EuCfWm-4xJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class train_ds_loader(Dataset):\n",
        "    def __init__(self):\n",
        "        self.ds = []\n",
        "        self.ds_len = 0\n",
        "\n",
        "        for r, d, files in os.walk('./features/'):\n",
        "            for file in files:\n",
        "              self.ds_len+=1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        loaded = np.load('./features/' + str(idx) +'.npy', allow_pickle=True)\n",
        "        waveform = torch.from_numpy(loaded[0])\n",
        "        waveform = torch.unsqueeze(waveform, 0)\n",
        "        label = loaded[1] - 1\n",
        "        return waveform, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.ds_len"
      ],
      "metadata": {
        "id": "uvgNYftG1Tb3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds_loader()"
      ],
      "metadata": {
        "id": "ij40F4VmItRp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=80, shuffle=True)"
      ],
      "metadata": {
        "id": "Ea9EYljrIxNZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Squeeze and excitation блок из статьи (tf-SE)"
      ],
      "metadata": {
        "id": "RQJAZHC3_TF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SE(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.fgate = nn.Sequential(nn.Linear(channels, channels), nn.Sigmoid())\n",
        "        self.tgate = nn.Sequential(nn.Linear(channels, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        fg = self.fgate(x.mean(dim=-1))\n",
        "        x = x * fg.unsqueeze(-1)\n",
        "        tg = x.permute(0, 2, 1).contiguous().view(-1, x.shape[1])\n",
        "        tg = self.tgate(tg).view(x.shape[0], x.shape[2]).unsqueeze(1)\n",
        "        out = x * tg\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "G8apYcmIM-bO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y = tf-SE(ReLU(Norm(Dropout(Conv(X))) \n",
        "\n",
        "DSConv это ReLU(Norm(Dropout(Conv(X))"
      ],
      "metadata": {
        "id": "bOJyF5dH_nKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DSConv(nn.Module):\n",
        "    def __init__(self, n_in, n_out, kernel, stride, padding=0):\n",
        "        super(DSConv, self).__init__()\n",
        "        self.conv = nn.Conv1d(n_in, n_out, kernel, stride=stride, padding=padding,bias=False)\n",
        "        self.norm = nn.GroupNorm(n_out, n_out, affine=False)\n",
        "        self.activation = nn.ReLU()\n",
        "              \n",
        "    def forward(self, x):\n",
        "      out = self.conv(x)\n",
        "      out = self.norm(out)\n",
        "      out = self.activation(out)\n",
        "      return out"
      ],
      "metadata": {
        "id": "y4miwL_-ZdE4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi Scale Feature Extraction Module. \n",
        "В сравнении с оригинальной работой изменен второй сверточный слой, который в стате называется dimension match convolution. Так вот, в коде автора этот слой не матчил размерности, часть вектора там просто обрезается. Изменен также выход сети, т.к. в коде автора на выход идет три блока skip1, skip2, tfSE3, хотя в самой статье преполагается skip1, skip2, skip3, tfSE3"
      ],
      "metadata": {
        "id": "cv1VSuNzAHor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "n7PaB3GMIz9_"
      },
      "outputs": [],
      "source": [
        "# Multi Scale Feature Extraction Module\n",
        "class MSFEM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MSFEM, self).__init__()\n",
        "\n",
        "        # MISSMATCHED DIM FROM PAPER\n",
        "        #par_conv1 = nn.Sequential(nn.Conv1d(1, 90, 12, 6), nn.Conv1d(90, 160, 5, 3))\n",
        "        #par_conv2 = nn.Sequential(nn.Conv1d(1, 90, 18, 9), nn.Conv1d(90, 160, 5, 2))\n",
        "        #par_conv3 = nn.Sequential(nn.Conv1d(1, 90, 36, 18), nn.Conv1d(90, 192, 5, 1))\n",
        "\n",
        "        #Matched Dimesions\n",
        "        self.par_conv1 = nn.Sequential(nn.Conv1d(1, 90, 12, 6), nn.Conv1d(90, 160, 5, 3))\n",
        "        self.par_conv2 = nn.Sequential(nn.Conv1d(1, 90, 18, 9), nn.Conv1d(90, 160, 3, 2))\n",
        "        self.par_conv3 = nn.Sequential(nn.Conv1d(1, 90, 36, 18), nn.Conv1d(90, 160, 1, 1))\n",
        "\n",
        "        self.skip1 = nn.MaxPool1d(kernel_size=5, stride=8)\n",
        "        self.skip2 = nn.MaxPool1d(kernel_size=3, stride=4, padding=1)\n",
        "        self.skip3 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.tfSE1 = nn.Sequential(DSConv(480, 480, 5, 2), SE(480))\n",
        "        self.tfSE2 = nn.Sequential(DSConv(480, 480, 3, 2), SE(480))\n",
        "        self.tfSE3 = nn.Sequential(DSConv(480, 480, 3, 2, padding=1), SE(480))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.par_conv1(x)\n",
        "        x2 = self.par_conv2(x)\n",
        "        x3 = self.par_conv3(x)\n",
        "        x_filtered_cat = torch.cat((x1, x2, x3), dim=1)\n",
        "        \n",
        "        x_skip1 = self.skip1(x_filtered_cat)\n",
        "        x_SE1 = self.tfSE1(x_filtered_cat)\n",
        "        x_skip2 = self.skip2(x_SE1)\n",
        "        x_SE2 = self.tfSE2(x_SE1)\n",
        "        x_skip3 = self.skip3(x_SE2)\n",
        "        x_SE3 = self.tfSE3(x_SE2)\n",
        "        out = torch.cat((x_SE3, x_skip3, x_skip2, x_skip1), dim=1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TDNNLayer(nn.Module):\n",
        "\n",
        "    # FROM https://github.com/cvqluu/TDNN/blob/master/tdnn.py\n",
        "\n",
        "    def __init__(self, input_dim, output_dim,\n",
        "                 context_size, dilation=1):\n",
        "        super(TDNNLayer, self).__init__()\n",
        "        self.context_size = context_size\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dilation = dilation\n",
        "        self.kernel = nn.Linear(input_dim*context_size, output_dim)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        # ----------Convolution = unfold + matmul + fold\n",
        "        x = inputs\n",
        "        _, d, _ = x.shape\n",
        "        assert (d == self.input_dim), 'Input dimension was wrong. Expected ({}), got ({})'.format(self.input_dim, d)\n",
        "        x = x.unsqueeze(1)\n",
        "        \n",
        "        # Unfold input into smaller temporal contexts\n",
        "        x = torch.nn.functional.unfold(x, (self.input_dim, self.context_size), \n",
        "                     stride=(self.input_dim, 1), \n",
        "                     dilation=(1, self.dilation))\n",
        "\n",
        "        # N, output_dim*context_size, new_t = x.shape\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.kernel(x) # matmul\n",
        "        \n",
        "        # transpose to channel first\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "V9TKvrQUQHtJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TDNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=460, context_size=5, dilation=1):\n",
        "        super(TDNN, self).__init__()\n",
        "\n",
        "        self.tdnn_layer = TDNNLayer(input_dim, output_dim, context_size, dilation)\n",
        "        self.norm = nn.GroupNorm(1, output_dim, affine=True)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.tdnn_layer(x)\n",
        "        out = self.norm(out)\n",
        "        out = self.activation(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "huOiecmqQqWa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TDNN "
      ],
      "metadata": {
        "id": "XNl1yaX8EVkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgregationTDNN(nn.Module):\n",
        "    def __init__(self, feature_dim=460, embed_dim=512, p_dropout=0.0):\n",
        "        super(AgregationTDNN, self).__init__()\n",
        "        self.tdnn = nn.Sequential(\n",
        "            TDNN(feature_dim, 460, 5, 1),\n",
        "            TDNN(460, 460, 3, 2),\n",
        "            TDNN(460, 460, 3, 3),\n",
        "            TDNN(460, 460, 1, 1),\n",
        "            TDNN(460, 1500, 1, 1),\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(3000, 460)\n",
        "        self.bn = nn.BatchNorm1d(460)\n",
        "        self.dropout_fc1 = nn.Dropout(p=p_dropout)\n",
        "        self.lrelu = nn.LeakyReLU(0.2)\n",
        "        self.fc2 = nn.Linear(460, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Note: x must be (batch_size, feat_dim, chunk_len)\n",
        "        x = self.tdnn(x)\n",
        "        \n",
        "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
        "        \n",
        "        x = self.dropout_fc1(self.lrelu(self.bn(self.fc1(stats))))\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "kmbPqmpEQ6RQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YVector "
      ],
      "metadata": {
        "id": "tM-I1ce6EZCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YVector(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(YVector, self).__init__()\n",
        "        self.MSFEM = MSFEM()\n",
        "        self.tdnn_aggregator = AgregationTDNN(feature_dim=480*4, embed_dim=embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.MSFEM(x)\n",
        "        out = self.tdnn_aggregator(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "yThkVmSLPN58"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Additive Margin Softmax"
      ],
      "metadata": {
        "id": "5qcTd26vFagQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdMSoftmaxLoss(nn.Module):\n",
        "    # FROM https://github.com/Leethony/Additive-Margin-Softmax-Loss-Pytorch/blob/master/AdMSLoss.py\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.4):\n",
        "        '''\n",
        "        AM Softmax Loss\n",
        "        '''\n",
        "        super(AdMSoftmaxLoss, self).__init__()\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        '''\n",
        "        input shape (N, in_features)\n",
        "        '''\n",
        "        assert len(x) == len(labels)\n",
        "        assert torch.min(labels) >= 0\n",
        "        assert torch.max(labels) < self.out_features\n",
        "        \n",
        "        for W in self.fc.parameters():\n",
        "            W = nn.functional.normalize(W, dim=1)\n",
        "\n",
        "        x = nn.functional.normalize(x, dim=1)\n",
        "\n",
        "        wf = self.fc(x)\n",
        "        numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
        "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
        "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
        "        L = numerator - torch.log(denominator)\n",
        "        return -torch.mean(L)"
      ],
      "metadata": {
        "id": "-mPokDPlsJm0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YVector().to(device)\n",
        "loss_function = AdMSoftmaxLoss(embedding_dim, num_classes).to(device)\n",
        "model.load_state_dict(torch.load('./drive/MyDrive/YVector/v5/yvector_model_v5_e0.pt'))\n",
        "loss_function.load_state_dict(torch.load('./drive/MyDrive/YVector/v4/yvector_loss_v4_e7.pt'))\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "tEMjUHNQObGn"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_function(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        if batch % 50 == 0:\n",
        "            #torch.cuda.empty_cache()\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "LOQLkxuaNPBx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "    test_loss /= num_batches\n",
        "    epochs_loss.append(test_loss)\n",
        "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "nm_au6zCPm26"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./drive/MyDrive/YVector/v6"
      ],
      "metadata": {
        "id": "doE20XCmPg64"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_loss = []\n",
        "epochs = 30\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    torch.save(model.state_dict(), './drive/MyDrive/YVector/v6/yvector_model_v6_e'+ str(t) +'.pt')\n",
        "    torch.save(loss_function.state_dict(), './drive/MyDrive/YVector/v6/yvector_loss_v6_e'+ str(t) +'.pt')\n",
        "    train(train_dl, model, loss_function, optimizer)\n",
        "    #test(test_dataloader, model, loss_function)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "rX9P-zacQf2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Equal Error Rate\n"
      ],
      "metadata": {
        "id": "LqWbxIT2GeZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_eer(positive_sim, negative_sim):\n",
        "    #From https://github.com/gzhu06/Y-vector/blob/main/eer_monitor.py\n",
        "    target_scores = sorted(positive_sim)\n",
        "    nontarget_scores = sorted(negative_sim)\n",
        "\n",
        "    target_size = len(target_scores)\n",
        "    nontarget_size = len(nontarget_scores)\n",
        "\n",
        "    target_position = 0\n",
        "    for target_position in range(target_size):\n",
        "        nontarget_n = nontarget_size * target_position * 1.0 / target_size\n",
        "        nontarget_position = int(nontarget_size - 1 - nontarget_n)\n",
        "        if nontarget_position < 0:\n",
        "            nontarget_position = 0\n",
        "        if nontarget_scores[nontarget_position] < target_scores[target_position]:\n",
        "            break\n",
        "\n",
        "    threshold = target_scores[target_position]\n",
        "    eer = target_position * 1.0 / target_size\n",
        "\n",
        "    return eer, threshold"
      ],
      "metadata": {
        "id": "zCyZrVWs0T7R"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./veri_test.txt', 'r') as f:\n",
        "    data = f.readlines()\n",
        "    positive_similarity = []\n",
        "    negative_similarity = []\n",
        "    prefix = './test/wav/'\n",
        "    sample_len = int(np.ceil(16000 * 3.9))\n",
        "    model.eval()\n",
        "    for line in tqdm(data, desc='Computing cosine similarities'):\n",
        "        content = line.split(' ')\n",
        "        file1 = content[1].split('.')[0]\n",
        "        file2 = content[2][:-1].split('.')[0]\n",
        "        path1 = prefix + file1 + '.wav'\n",
        "        path2 = prefix + file2 + '.wav'\n",
        "        waveform1, sr = librosa.load(path1, sr=None)\n",
        "        waveform2, sr = librosa.load(path2, sr=None)\n",
        "        waveform1 = librosa.util.normalize(waveform1)\n",
        "        waveform2 = librosa.util.normalize(waveform2)\n",
        "        waveform1 = waveform1[:sample_len]\n",
        "        waveform2 = waveform2[:sample_len]\n",
        "        waveform1 = torch.from_numpy(waveform1)\n",
        "        waveform2 = torch.from_numpy(waveform2)\n",
        "        waveform1 = torch.unsqueeze(waveform1, 0)\n",
        "        waveform1 = torch.unsqueeze(waveform1, 0)\n",
        "        waveform2 = torch.unsqueeze(waveform2, 0)\n",
        "        waveform2 = torch.unsqueeze(waveform2, 0)\n",
        "        waveform1 = waveform1.to(device)\n",
        "        waveform2 = waveform2.to(device)\n",
        "        anchor_embeds = model(waveform1).squeeze(0)\n",
        "        pair_embeds = model(waveform2).squeeze(0)\n",
        "        sims_temp = torch.nn.functional.cosine_similarity(anchor_embeds, pair_embeds, dim=0).cpu().detach().numpy()\n",
        "        if content[0] == '1':\n",
        "            positive_similarity.append(sims_temp)\n",
        "        if content[0] == '0':\n",
        "            negative_similarity.append(sims_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6rdUDvS0U6u",
        "outputId": "5438ca0e-8fbd-4170-b75a-90861df90d1e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing cosine similarities: 100%|██████████| 37720/37720 [21:17<00:00, 29.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_similarity = np.array(positive_similarity)\n",
        "negative_similarity = np.array(negative_similarity)"
      ],
      "metadata": {
        "id": "r0p0PmHoEM2r"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eer, threshold = eval_eer(positive_similarity, negative_similarity)\n",
        "print(\"threshold is --> {:.4f}\".format(threshold), \"eer is --> {:.4f}%\".format(eer*100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8ExtOIzAXfC",
        "outputId": "216c4329-fcb0-4b56-a6ee-2d2aecd84044"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold is --> 0.3013 eer is --> 28.3775%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cuda Memory Release\n",
        "import gc\n",
        "\n",
        "model.cpu()\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ad7lMKy-kUZM"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}